<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Personal website of Lorenzo Baraldi, PhD sudent at Unimore.">
	<meta name="author" content="Lorenzo Baraldi">
    <title>Lorenzo Baraldi - PhD Student</title>
    <link href="./bootstrap/css/bootstrap.min.css" rel="stylesheet">
	<link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="style.css" />
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-39563464-1', 'auto');
	  ga('require', 'displayfeatures');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <div class="header">
      <div class="container">
        <div class="row">
          <div class="col-md-5">
            <h1>Lorenzo Baraldi</h1>
          </div>
        </div>
        <div class="row spacer">
          <div class="col-md-2">
            <img src="images/pic.JPG" class="img-rounded" width="150"/>
          </div>
          <div class="col-md-9">
            PhD Student @ <a href="http://imagelab.ing.unimore.it">Imagelab</a><br />
            <a href="http://www.ing.unimore.it">Engineering Department</a><br />
            <a href="http://www.unimore.it">University of Modena and Reggio Emilia</a> <br /> <br />
            <ul class="list-unstyled">
              <li>Email: <a href="mailto:baraldi.lorenzo(at)gmail(dot)com">baraldi.lorenzo (at) gmail (dot) com</a></li>
              <li>Curriculum: <a href="curriculum.pdf">C.V.</a></li>
			  <li><a href="https://twitter.com/lorenzo_baraldi" class="icon"><i class="fa fa-twitter fa-lg"></i></a>&nbsp;<a href="http://it.linkedin.com/pub/lorenzo-baraldi/83/164/8b" class="icon"><i class="fa fa-linkedin fa-lg"></i></a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h2>News</h2>
		  <ul>
			<li>Accepted <a href="http://imagelab.ing.unimore.it/scenedemo">demo</a> at <a href="http://www.ibpria.org/2015/">IbPRIA 2015</a></li>
			<li>Accepted paper at <a href="http://www.icme2015.ieee-icme.org">ICME 2015</a></li>
			<li>Accepted paper for publication in the IEEE Sensors Journal</li>
		  </ul>
        </div>
      </div>	
      <div class="row">
        <div class="col-md-12">
          <h2>Publications</h2>
        </div>
      </div>
      <div class="row">
        <div class="col-md-9">
          <h4>Scene segmentation using Temporal Clustering for Accessing and Re-using Broadcast Video</h4>
          <h5>L. Baraldi, C. Grana, R. Cucchiara, ICME 2015</h5>
          <p>Scene detection is a fundamental tool for allowing effective video browsing and re-using. In this paper we present a model that automatically divides videos into coherent scenes, which is based on a novel combination of local image descriptors and temporal clustering techniques. Experiments are performed to demonstrate the effectiveness of our approach, by comparing our algorithm against two recent proposals for automatic scene segmentation. We also propose improved performance measures that aim to reduce the gap between numerical evaluation and expected results.</p>
          <a href="http://imagelab.ing.unimore.it/imagelab/pubblicazioni/2015ICME.pdf"><button type="button" class="btn btn-primary btn-sm">PDF</button></a>
        </div>
      </div>
      <hr>
      <div class="row">
        <div class="col-md-9">
          <h4>Measuring Scene Detection Performance</h4>
          <h5>L. Baraldi, C. Grana, R. Cucchiara, IbPRIA 2015</h5>
          <p>In this paper we evaluate the performance of scene detection techniques, starting from the classic precision/recall approach, moving to the better designed coverage/overflow measures, and finally proposing an improved metric, in order to solve frequently observed cases in which the numeric interpretation is different from the expected results. Numerical evaluation is performed on two recent proposals for automatic scene detection, and comparing them with a simple but effective novel approach. Experimental results are conducted to show how different measures may lead to different interpretations.</p>
          <a href="http://imagelab.ing.unimore.it/imagelab/pubblicazioni/2015IbPRIA.pdf"><button type="button" class="btn btn-primary btn-sm">PDF</button></a>
        </div>
      </div>
      <hr>
      <div class="row">
        <div class="col-md-9">
          <h4>Analysis and Re-use of Videos in Educational Digital Libraries with Automatic Scene Detection</h4>
          <h5>L. Baraldi, C. Grana, R. Cucchiara, IRCDL 2015</h5>
          <p>The advent of modern approaches to education, like Massive Open Online Courses (MOOC), made video the basic media for educating and transmitting knowledge. However, IT tools are still not adequate to allow video content re-use, tagging, annotation and personalization. In this paper we analyze the problem of identifying coherent sequences, called scenes, in order to provide the users with a more manageable editing unit. A simple spectral clustering technique is proposed and compared with state-of-the-art results. We also discuss correct ways to evaluate the performance of automatic scene detection algorithms.</p>
          <a href="http://imagelab.ing.unimore.it/imagelab/pubblicazioni/2015IRCDL.pdf"><button type="button" class="btn btn-primary btn-sm">PDF</button></a>
        </div>
      </div>	  
      <hr>
      <div class="row">
        <div class="col-md-9">
          <h4>Gesture Recognition using Wearable Vision Sensors to Enhance Visitors' Museum Experiences</h4>
          <h5>L. Baraldi, F. Paci, G. Serra, L. Benini, R. Cucchiara, in press on IEEE Sensors Journal</h5>
          <p>We introduce a novel approach to cultural heritage experience: by means of ego-vision embedded devices we develop a system which offers a more natural and entertaining way of accessing museum knowledge. Our method is based on distributed self-gesture and artwork recognition, and does not need fixed cameras nor RFIDs sensors. We propose the use of dense trajectories sampled around the hand region to perform selfgesture recognition, understanding the way a user naturally interacts with an artwork, and demonstrate that our approach can benefit from distributed training. We test our algorithms on publicly available datasets and we extend our experiments to both virtual and real museum scenarios where our method shows robustness when challenged with real-world data. Furthermore, we run an extensive performance analysis on our ARM-based wearable device.</p>
          <a href="http://dx.doi.org/10.1109/JSEN.2015.2411994"><button type="button" class="btn btn-primary btn-sm">PDF</button></a>
        </div>
        <div class="col-md-3">
          <img class="img-responsive" src="papers/ieee_sens15.jpg" alt="">
        </div>	        
      </div>
      <hr>	  
      <div class="row">
        <div class="col-md-9">
          <h4>Gesture Recognition in Ego-Centric Videos using Dense Trajectories and Hand Segmentation</h4>
          <h5>L. Baraldi, F. Paci, G. Serra, L. Benini, R. Cucchiara, Embedded Vision Workshop CVPR 2014</h5>
          <p>We present a novel method for monocular hand gesture recognition in ego-vision scenarios that deals with static and dynamic gestures and can achieve high accuracy results using a few positive samples. Specifically, we use and extend the dense trajectories approach that has been successfully introduced for action recognition. Dense features are extracted around regions selected by a new hand segmentation technique that integrates superpixel classification, temporal and spatial coherence. We extensively test our gesture recognition and segmentation algorithms on public datasets and propose a new dataset shot with a wearable camera. In addition, we demonstrate that our solution can work in near real-time on a wearable device.</p>
          <a href="papers/evw14.pdf"><button type="button" class="btn btn-primary btn-sm">PDF</button></a> <button type="button" class="btn btn-default btn-sm" data-toggle="modal" data-target="#VideoGR">Video</button> <a href="http://imagelab.ing.unimore.it/files/ego_virtualmuseum.zip"><button type="button" class="btn btn-default btn-sm">Dataset</button></a>
        </div>
        <div class="col-md-3">
          <img class="img-responsive" src="papers/evw14.jpg" alt="">
        </div>
      </div>
      <hr>
      <div class="row">
        <div class="col-md-9">
          <h4>Hand Segmentation for Gesture Recognition in EGO-Vision</h4>
          <h5>G. Serra, M. Camurri, L. Baraldi, M. Benedetti, R. Cucchiara, IMMPD, 2013</h5>
          <p>We provide a hand segmentation algorithm based on Random Forest superpixel classification that integrates light, time and space consistency. We also propose a gesture recognition method based Exemplar SVMs since it requires a only small set of positive sampels, hence it is well suitable for the egocentric video applications. Furthermore, this method is enhanced  by using segmented images instead of full frames during test phase. Experimental results show that our hand segmentation algorithm outperforms the state-of-the-art approaches and improves the gesture recognition accuracy.</p>
          <a href="papers/immpd13.pdf"><button type="button" class="btn btn-primary btn-sm">PDF</button></a> <button type="button" class="btn btn-default btn-sm" data-toggle="modal" data-target="#VideoHS">Video</button>
        </div>
        <div class="col-md-3">
          <img class="img-responsive" src="papers/immpd13.jpg" alt="">
        </div>		
      </div>
      <div class="row">
        <div class="col-md-12">
          <h2>Education</h2>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <dl class="dl-horizontal">
            <dt>Bachelor Degree</dt>
            <dd>B.Sc. in Computer Engineering, 2011<br />
              University of Modena and Reggio Emilia<br />
              Mark: 110/110 cum laude
            </dd>
          </dl>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <dl class="dl-horizontal">
            <dt>Master Degree</dt>
            <dd>M.Sc. in Computer Engineering, 2014<br />
              University of Modena and Reggio Emilia<br />
              Mark: 110/110 cum laude
            </dd>
          </dl>
        </div>
      </div>	  
      <footer>
        <div class="row">
          <div class="col-md-12">
            <p>Last update: March 2015</p>
          </div>
        </div>
      </footer>
    </div>
	
	<div class="modal fade" id="VideoGR" tabindex="-1" role="dialog" aria-labelledby="VideoGRLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
					<h4 class="modal-title" id="VideoGRLabel">Gesture Recognition in Ego-Vision</h4>
				</div>
				<div class="modal-body">
					<div class="video"><iframe src="http://player.vimeo.com/video/107716179?autoplay=1" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div>
				</div>
			</div>
		</div>
	</div>
	
	<div class="modal fade" id="VideoHS" tabindex="-1" role="dialog" aria-labelledby="VideoHSLabel" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
					<h4 class="modal-title" id="VideoHSLabel">Hand Segmentation in Ego-Vision</h4>
				</div>
				<div class="modal-body">
					<div class="video"><iframe src="http://player.vimeo.com/video/78178993?autoplay=1" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div>
				</div>
			</div>
		</div>
	</div>	
    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script src="./bootstrap/js/bootstrap.min.js"></script>
  </body>
</html>
